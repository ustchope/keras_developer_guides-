{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opposed-tackle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 519 ms (started: 2021-08-26 20:52:58 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 自动计算cell的计算时间\n",
    "%load_ext autotime\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='svg' #矢量图设置，让绘图更清晰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intellectual-trunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\tgit@github.com:ustchope/keras_developer_guides-.git (fetch)\n",
      "origin\tgit@github.com:ustchope/keras_developer_guides-.git (push)\n",
      "[main 9fad412] 更新 #9  Aug 26, 2021\n",
      " 2 files changed, 1971 insertions(+), 2 deletions(-)\n",
      " create mode 100644 Keras FAQ.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To git@github.com:ustchope/keras_developer_guides-.git\n",
      "   98ea9e4..9fad412  main -> main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.47 s (started: 2021-08-26 20:53:17 +08:00)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# 增加更新\n",
    "git add *.ipynb *.md\n",
    "\n",
    "git remote -v\n",
    "\n",
    "git commit -m '更新 #9  Aug 26, 2021'\n",
    "\n",
    "#git push origin master\n",
    "git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mighty-pontiac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.01 s (started: 2021-08-26 20:53:38 +08:00)\n"
     ]
    }
   ],
   "source": [
    "#设置使用的gpu\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpus:\n",
    "   \n",
    "    gpu0 = gpus[0] #如果有多个GPU，仅使用第0个GPU\n",
    "    tf.config.experimental.set_memory_growth(gpu0, True) #设置GPU显存用量按需使用\n",
    "    # 或者也可以设置GPU显存为固定使用量(例如：4G)\n",
    "    #tf.config.experimental.set_virtual_device_configuration(gpu0,\n",
    "    #    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) \n",
    "    tf.config.set_visible_devices([gpu0],\"GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "complex-record",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.15 ms (started: 2021-08-26 20:53:46 +08:00)\n"
     ]
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-thinking",
   "metadata": {},
   "source": [
    "# 一般的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-heath",
   "metadata": {},
   "source": [
    "## 如何在多个 GPU 上（在一台机器上）训练 Keras 模型？\n",
    "有两种方法可以在多个 GPU 上运行单个模型：数据并行和设备并行。 在大多数情况下，您最需要的是数据并行性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-probe",
   "metadata": {},
   "source": [
    "### 数据并行\n",
    "\n",
    "数据并行包括在每个设备上复制目标模型一次，并使用每个副本来处理输入数据的不同部分。\n",
    "\n",
    "使用 Keras 模型进行数据并行的最佳方法是使用 tf.distribute API。 请务必阅读我们关于在 Keras 中使用 [tf.distribute](https://www.tensorflow.org/api_docs/python/tf/distribute) 的指南。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-reynolds",
   "metadata": {},
   "source": [
    "它的要点如下：\n",
    "\n",
    "a) 实例化一个“分发策略”对象，例如 MirroredStrategy（在每个可用设备上复制您的模型并保持每个模型的状态同步）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "humanitarian-westminster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:NCCL is not supported when using virtual GPUs, fallingback to reduction to one device\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "time: 1.41 s (started: 2021-08-26 21:10:46 +08:00)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-humanity",
   "metadata": {},
   "source": [
    "b) 创建您的模型并在策略范围内编译它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vulnerable-spice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "time: 1.03 s (started: 2021-08-26 21:11:34 +08:00)\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    # This could be any kind of model -- Functional, subclass...\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "        tf.keras.layers.GlobalMaxPooling2D(),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  optimizer=tf.keras.optimizers.Adam(),\n",
    "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-mounting",
   "metadata": {},
   "source": [
    "请注意，所有状态变量的创建都应在作用域下进行，这一点很重要。 因此，如果您创建任何其他变量，请在范围内进行。\n",
    "\n",
    "c) 使用 tf.data.Dataset 对象作为输入调用 fit()。 分发与所有回调广泛兼容，包括自定义回调。 请注意，此调用不需要在策略范围内，因为它不会创建新变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-liberal",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs=12, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-claim",
   "metadata": {},
   "source": [
    "### 模型并行\n",
    "\n",
    "模型并行包括在不同设备上运行同一模型的不同部分。 它最适用于具有并行架构的模型，例如 一个有两个分支的模型。\n",
    "\n",
    "这可以通过使用 TensorFlow 设备范围来实现。 这是一个快速示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model where a shared LSTM is used to encode two different sequences in parallel\n",
    "input_a = keras.Input(shape=(140, 256))\n",
    "input_b = keras.Input(shape=(140, 256))\n",
    "\n",
    "shared_lstm = keras.layers.LSTM(64)\n",
    "\n",
    "# 在一个 GPU 上处理第一个序列\n",
    "with tf.device_scope('/gpu:0'):\n",
    "    encoded_a = shared_lstm(input_a)\n",
    "# 在另一个 GPU 上处理下一个序列\n",
    "with tf.device_scope('/gpu:1'):\n",
    "    encoded_b = shared_lstm(input_b)\n",
    "\n",
    "# 在 CPU 上连接结果\n",
    "with tf.device_scope('/cpu:0'):\n",
    "    merged_vector = keras.layers.concatenate(\n",
    "        [encoded_a, encoded_b], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-correlation",
   "metadata": {},
   "source": [
    "## 如何在多台机器上分配训练？\n",
    "TensorFlow 2 使您能够编写与分发方式基本无关的代码：任何可以在本地运行的代码都可以分发给多个工作程序和加速器，只需向其中添加与您的分发策略相对应的分发策略 (tf.distribute.Strategy)选择的硬件，无需任何其他代码更改。\n",
    "\n",
    "这也适用于任何 Keras 模型：只需添加一个包含模型构建和编译代码的 tf.distribute 分发策略范围，训练将根据 tf.distribute 分发策略进行分发。\n",
    "\n",
    "对于跨多台机器的分布式训练（与仅在一台机器上利用多个设备的训练相反），您可以使用两种分配策略：`MultiWorkerMirroredStrategy` 和 `ParameterServerStrategy`：\n",
    "* `tf.distribute.MultiWorkerMirroredStrategy` 实现了一个同步 CPU/GPU 多线程解决方案，以使用 Keras 风格的模型构建和训练循环，使用跨副本的梯度同步减少。\n",
    "* `tf.distribute.experimental.ParameterServerStrategy` 实现了一个异步的 CPU/GPU 多工作器解决方案，其中参数存储在参数服务器上，工作器异步更新梯度到参数服务器。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-example",
   "metadata": {},
   "source": [
    "分布式训练比单机多设备训练涉及更多。使用 ParameterServerStrategy，您将需要启动一个由“worker”和“ps”组成的远程机器集群，每个机器都运行一个 tf.distribute.Server，然后在拥有 TF_CONFIG 环境变量的“首席”机器上运行您的 python 程序如何与集群中的其他机器通信。使用 MultiWorkerMirroredStrategy，您将在每个主管和工作人员上运行相同的程序，同样使用 TF_CONFIG 环境变量指定如何与集群通信。从那里开始，工作流程类似于使用单机训练，主要区别在于您将使用 ParameterServerStrategy 或 MultiWorkerMirroredStrategy 作为您的分发策略。\n",
    "\n",
    "重要的是，您应该：\n",
    "* 确保您的数据集配置为集群中的所有工作人员都能够有效地从中提取数据（例如，如果您的集群在 GCP 上运行，则最好将您的数据托管在 Google Cloud Storage 上）。\n",
    "* 确保您的训练是容错的（例如，通过配置 keras.callbacks.BackupAndRestore 回调）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-kuwait",
   "metadata": {},
   "source": [
    "下面，我们提供了几个涵盖基本工作流程的代码片段。 有关 CPU/GPU 多工训练的更多信息，请参阅多 GPU 和分布式训练； 对于 TPU 训练，请参阅如何在 TPU 上训练 Keras 模型？。\n",
    "\n",
    "使用参数服务器策略："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_resolver = ...\n",
    "if cluster_resolver.task_type in (\"worker\", \"ps\"):\n",
    "  # Start a [`tf.distribute.Server`](https://www.tensorflow.org/api_docs/python/tf/distribute/Server) and wait.\n",
    "  ...\n",
    "elif cluster_resolver.task_type == \"evaluator\":\n",
    "  # Run an (optional) side-car evaluation\n",
    "  ...\n",
    "\n",
    "# Otherwise, this is the coordinator that controls the training w/ the strategy.\n",
    "strategy = tf.distribute.experimental.ParameterServerStrategy(\n",
    "    cluster_resolver=...)\n",
    "train_dataset = ...\n",
    "\n",
    "with strategy.scope():\n",
    "  model = tf.keras.Sequential([\n",
    "      layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(10, activation='softmax')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "      metrics=['accuracy'],\n",
    "      steps_per_execution=10)\n",
    "\n",
    "model.fit(x=train_dataset, epochs=3, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-aviation",
   "metadata": {},
   "source": [
    "使用 MultiWorkerMirroredStrategy："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default `MultiWorkerMirroredStrategy` uses cluster information\n",
    "# from `TF_CONFIG`, and \"AUTO\" collective op communication.\n",
    "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
    "train_dataset = get_training_dataset()\n",
    "with strategy.scope():\n",
    "  # Define and compile the model in the scope of the strategy. Doing so\n",
    "  # ensures the variables created are distributed and initialized properly\n",
    "  # according to the strategy.\n",
    "  model = tf.keras.Sequential([\n",
    "      layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
    "      layers.MaxPooling2D(),\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(10, activation='softmax')\n",
    "  ])\n",
    "  model.compile(\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "      metrics=['accuracy'])\n",
    "model.fit(x=train_dataset, epochs=3, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-peoples",
   "metadata": {},
   "source": [
    "## 如何在 TPU 上训练 Keras 模型？\n",
    "TPU 是一种快速高效的深度学习硬件加速器，可在 Google Cloud 上公开使用。 您可以通过 Colab、AI 平台（机器学习引擎）和深度学习虚拟机使用 TPU（前提是在虚拟机上设置了 TPU_NAME 环境变量）。\n",
    "\n",
    "请务必先阅读 TPU 使用指南。 这是一个快速总结：\n",
    "\n",
    "连接到 TPU 运行时（例如，通过在 Colab 中选择 TPU 运行时）后，您需要使用 TPUClusterResolver 检测您的 TPU，它会在所有支持的平台上自动检测链接的 TPU："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "print('Running on TPU: ', tpu.cluster_spec().as_dict()['worker'])\n",
    "\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "print('Replicas: ', strategy.num_replicas_in_sync)\n",
    "\n",
    "with strategy.scope():\n",
    "    # Create your model here.\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-abuse",
   "metadata": {},
   "source": [
    "初始设置后，工作流程类似于使用单机多 GPU 训练，主要区别在于您将使用 TPUStrategy 作为您的分发策略。\n",
    "\n",
    "重要的是，您应该：\n",
    "* 确保您的数据集产生具有固定静态形状的批次。 TPU 图只能处理具有恒定形状的输入。\n",
    "* 确保您能够以足够快的速度读取数据，以保持 TPU 的利用率。 使用 TFRecord 格式存储数据可能是个好主意。\n",
    "* 考虑在每次图执行时运行多个梯度下降步骤，以保持 TPU 的利用率。 您可以通过experimental_steps_per_execution 参数compile() 执行此操作。 它将为小型模型带来显着的加速。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-sampling",
   "metadata": {},
   "source": [
    "## Keras 配置文件存储在哪里？\n",
    "存储所有 Keras 数据的默认目录是：\n",
    "\n",
    "`$HOME/.keras/`\n",
    "\n",
    "例如，对我来说，在 MacBook Pro 上，它是 `/Users/fchollet/.keras/`。\n",
    "\n",
    "请注意，Windows 用户应将 `$HOME` 替换为 `%USERPROFILE%`。\n",
    "\n",
    "如果 Keras 无法创建上述目录（例如由于权限问题），则使用 `/tmp/.keras/` 作为备份。\n",
    "\n",
    "Keras 配置文件是一个 JSON 文件，存储在 `$HOME/.keras/keras.json` 中。 默认配置文件如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-problem",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"image_data_format\": \"channels_last\",\n",
    "    \"epsilon\": 1e-07,\n",
    "    \"floatx\": \"float32\",\n",
    "    \"backend\": \"tensorflow\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-oregon",
   "metadata": {},
   "source": [
    "它包含以下字段：\n",
    "* 图像处理层和实用程序（channels_last 或 channels_first）默认使用的图像数据格式。\n",
    "* 用于防止在某些操作中被零除的 epsilon 数值模糊因子。\n",
    "* 默认浮点数据类型。\n",
    "* 默认后端。 这是遗产； 现在只有 TensorFlow。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinated-brunswick",
   "metadata": {},
   "source": [
    "同样，缓存数据集文件，例如使用 `get_file()` 下载的文件，默认存储在 `$HOME/.keras/datasets/` 中，来自 Keras 应用程序的缓存模型权重文件默认存储在 `$HOME/.keras/models/` ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standing-fortune",
   "metadata": {},
   "source": [
    "## 如何使用 Keras 进行超参数调整？\n",
    "我们推荐使用 Keras Tuner。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weekly-responsibility",
   "metadata": {},
   "source": [
    "## 如何在开发过程中使用 Keras 获得可重现的结果？\n",
    "在模型的开发过程中，有时能够从一次运行中获得可重复的结果以确定性能变化是由于实际模型或数据修改引起的，还是仅仅是新随机种子的结果是很有用的。\n",
    "\n",
    "首先，您需要在程序启动之前（不在程序本身内）将 PYTHONHASHSEED 环境变量设置为 0。 在 Python 3.2.3 之后，这对于某些基于哈希的操作具有可重现的行为是必要的（例如，集合或字典中的项目顺序，请参阅 Python 的文档或问题 #2280 以获取更多详细信息）。 设置环境变量的一种方法是像这样启动 python 时："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ cat test_hash.py\n",
    "print(hash(\"keras\"))\n",
    "$ python3 test_hash.py                  # non-reproducible hash (Python 3.2.3+)\n",
    "8127205062320133199\n",
    "$ python3 test_hash.py                  # non-reproducible hash (Python 3.2.3+)\n",
    "3204480642156461591\n",
    "$ PYTHONHASHSEED=0 python3 test_hash.py # reproducible hash\n",
    "4883664951434749476\n",
    "$ PYTHONHASHSEED=0 python3 test_hash.py # reproducible hash\n",
    "4883664951434749476"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-thermal",
   "metadata": {},
   "source": [
    "此外，在 GPU 上运行时，某些操作具有不确定性输出，尤其是 tf.reduce_sum()。 这是因为 GPU 并行运行许多操作，因此无法始终保证执行顺序。 由于浮点数的精度有限，即使将几个数字相加也可能会产生略有不同的结果，具体取决于您添加它们的顺序。 您可以尝试避免非确定性操作，但有些操作可能由 TensorFlow 自动创建来计算梯度，因此在 CPU 上运行代码要简单得多。 为此，您可以将 CUDA_VISIBLE_DEVICES 环境变量设置为空字符串，例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ CUDA_VISIBLE_DEVICES=\"\" PYTHONHASHSEED=0 python your_program.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arbitrary-immigration",
   "metadata": {},
   "source": [
    "以下代码片段提供了如何获得可重现结果的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as python_random\n",
    "\n",
    "# 下面是在明确定义的初始状态下启动 Numpy 生成的随机数所必需的。\n",
    "np.random.seed(123)\n",
    "\n",
    "# 下面是启动核心 Python 生成的处于明确定义状态的随机数所必需的。\n",
    "python_random.seed(123)\n",
    "\n",
    "# 下面的 set_seed() 将使 TensorFlow 后端的随机数生成具有明确定义的初始状态。\n",
    "# For further details, see:\n",
    "# https://www.tensorflow.org/api_docs/python/tf/random/set_seed\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "# Rest of code follows ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-amount",
   "metadata": {},
   "source": [
    "请注意，如果您执行上述步骤，则不必在代码中为各个初始值设定项设置种子，因为它们的种子是由上面设置的种子组合决定的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-closer",
   "metadata": {},
   "source": [
    "## 我有哪些保存模型的选项？\n",
    "注意：不建议使用 pickle 或 cPickle 来保存 Keras 模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-kennedy",
   "metadata": {},
   "source": [
    "### 全模型保存（配置+权重）\n",
    "\n",
    "整个模型保存意味着创建一个文件，其中将包含：\n",
    "* 模型的架构，允许您重新创建模型\n",
    "* 模型的权重\n",
    "* 训练配置（损失，优化器）\n",
    "* 优化器的状态，允许您从中断的地方继续训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-placement",
   "metadata": {},
   "source": [
    "默认和推荐使用的格式是 TensorFlow SavedModel 格式。 在 TensorFlow 2.0 及更高版本中，您只需执行以下操作：`model.save(your_file_path)`。\n",
    "\n",
    "为了明确起见，您还可以使用 `model.save(your_file_path, save_format='tf')`。\n",
    "\n",
    "Keras 仍然支持其原始的基于 HDF5 的保存格式。 要将模型保存为 HDF5 格式，请使用 `model.save(your_file_path, save_format='h5')`。 请注意，如果 your_file_path 以 .h5 或 .keras 结尾，则会自动使用此选项。 另请参阅如何安装 HDF5 或 h5py 来保存我的模型？ 有关如何安装 h5py 的说明。\n",
    "\n",
    "以任一格式保存模型后，您可以通过 `model = keras.models.load_model(your_file_path)` 重新实例化它。\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "billion-labor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Assets written to: my_model/assets\n",
      "time: 792 ms (started: 2021-08-26 21:26:17 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('my_model')  # creates a HDF5 file 'my_model.h5'\n",
    "del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('my_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "settled-partner",
   "metadata": {},
   "source": [
    "### 仅保存权重\n",
    "\n",
    "如果您需要保存模型的权重，您可以在 HDF5 中使用以下代码执行此操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-belly",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-malaysia",
   "metadata": {},
   "source": [
    "假设您有用于实例化模型的代码，然后您可以将保存的权重加载到具有相同架构的模型中："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-assessment",
   "metadata": {},
   "source": [
    "如果您需要将权重加载到不同的架构中（某些层是相同的），例如用于微调或迁移学习，您可以按层名称加载它们："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('my_model_weights.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-roots",
   "metadata": {},
   "source": [
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-vehicle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Assuming the original model looks like this:\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=3, name='dense_1'))\n",
    "model.add(Dense(3, name='dense_2'))\n",
    "...\n",
    "model.save_weights(fname)\n",
    "\"\"\"\n",
    "\n",
    "# new model\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=3, name='dense_1'))  # will be loaded\n",
    "model.add(Dense(10, name='new_dense'))  # will not be loaded\n",
    "\n",
    "# load weights from the first model; will only affect the first layer, dense_1.\n",
    "model.load_weights(fname, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-compromise",
   "metadata": {},
   "source": [
    "另请参阅如何安装 HDF5 或 h5py 来保存我的模型？ 有关如何安装 h5py 的说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-mortality",
   "metadata": {},
   "source": [
    "### 仅配置保存（序列化）\n",
    "\n",
    "如果您只需要保存模型的架构，而不是其权重或训练配置，您可以执行以下操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as JSON\n",
    "json_string = model.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "australian-diagnosis",
   "metadata": {},
   "source": [
    "生成的 JSON 文件是人类可读的，如果需要，可以手动编辑。\n",
    "\n",
    "然后，您可以根据这些数据构建一个新模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model reconstruction from JSON:\n",
    "from tensorflow.keras.models import model_from_json\n",
    "model = model_from_json(json_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-tribune",
   "metadata": {},
   "source": [
    "### 在保存的模型中处理自定义层（或其他自定义对象）\n",
    "\n",
    "如果您要加载的模型包含自定义层或其他自定义类或函数，您可以通过 custom_objects 参数将它们传递给加载机制："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# Assuming your model includes instance of an \"AttentionLayer\" class\n",
    "model = load_model('my_model.h5', custom_objects={'AttentionLayer': AttentionLayer})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-michael",
   "metadata": {},
   "source": [
    "或者，您可以使用自定义对象范围："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import CustomObjectScope\n",
    "\n",
    "with CustomObjectScope({'AttentionLayer': AttentionLayer}):\n",
    "    model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mounted-conditioning",
   "metadata": {},
   "source": [
    "自定义对象处理与 load_model 和 model_from_json 的工作方式相同："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "model = model_from_json(json_string, custom_objects={'AttentionLayer': AttentionLayer})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-bhutan",
   "metadata": {},
   "source": [
    "### 我应该如何引用 Keras？\n",
    "如果对您的研究有帮助，请在您的出版物中引用 Keras。 这是一个示例 BibTeX 条目："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "@misc{chollet2015keras,\n",
    "  title={Keras},\n",
    "  author={Chollet, Fran\\c{c}ois and others},\n",
    "  year={2015},\n",
    "  howpublished={\\url{https://keras.io}},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-ministry",
   "metadata": {},
   "source": [
    "# 训练相关问题\n",
    "## \"sample\", \"batch\", 和 \"epoch\"是什么意思？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-framework",
   "metadata": {},
   "source": [
    "以下是正确使用 Keras fit() 需要了解和理解的一些常见定义：\n",
    "* 样本：数据集的一个元素。例如，一张图像是卷积网络中的一个样本。一个音频片段是语音识别模型的示例。\n",
    "* 批次：一组 N 个样本。批次中的样品独立、并行处理。如果是训练，批处理只会导致模型更新一次。批处理通常比单个输入更接近输入数据的分布。批量越大，近似越好；但是，批处理将需要更长的时间来处理并且仍然只会导致一次更新，这也是事实。对于推理（评估/预测），建议在不耗尽内存的情况下选择尽可能大的批次大小（因为更大的批次通常会导致更快的评估/预测）。\n",
    "* Epoch：任意截止，通常定义为“一次遍历整个数据集”，用于将训练分成不同的阶段，这对于记录和定期评估很有用。当将 validation_data 或 validation_split 与 Keras 模型的 fit 方法一起使用时，评估将在每个 epoch 结束时运行。在 Keras 中，可以添加专门设计为在 epoch 结束时运行的回调。这些示例包括学习率变化和模型检查点（保存）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-spouse",
   "metadata": {},
   "source": [
    "## 为什么我的训练损失比我的测试损失高得多？\n",
    "Keras 模型有两种模式：训练和测试。 在测试时关闭正则化机制，例如 Dropout 和 L1/L2 权重正则化。 它们反映在训练时间损失中，而不是测试时间损失中。\n",
    "\n",
    "此外，Keras 显示的训练损失是当前时期内每批训练数据的平均损失。 由于您的模型随着时间的推移而发生变化，因此一个 epoch 的第一批的损失通常高于最后一批的损失。 这可以降低时代平均水平。 另一方面，一个 epoch 的测试损失是使用模型计算的，因为它在 epoch 结束时，导致较低的损失。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-myrtle",
   "metadata": {},
   "source": [
    "## 如何将 Keras 与不适合内存的数据集一起使用？\n",
    "你应该使用 `tf.data API` 来创建 `tf.data.Dataset` 对象——一个对数据管道的抽象，它可以从本地磁盘、分布式文件系统、GCS 等中提取数据，并有效地应用各种 数据转换。\n",
    "\n",
    "例如，实用程序 [tf.keras.preprocessing.image_dataset_from_directory](/api/preprocessing/image#imagedatasetfromdirectory-function) 将创建一个从本地目录读取图像数据的数据集。 同样，实用程序 [tf.keras.preprocessing.text_dataset_from_directory](/api/preprocessing/text#textdatasetfromdirectory-function) 将创建一个从本地目录读取文本文件的数据集。\n",
    "\n",
    "数据集对象可以直接传递给 fit()，也可以在自定义的低级训练循环中迭代。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(dataset, epochs=10, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-equation",
   "metadata": {},
   "source": [
    "## 我如何确保我的训练可以从程序中断中恢复？\n",
    "为确保能够随时从中断的训练运行中恢复（容错），您应该使用 tf.keras.callbacks.experimental.BackupAndRestore 定期将您的训练进度（包括时期数和权重）保存到磁盘，以及 下次调用 Model.fit() 时加载它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "class InterruptingCallback(keras.callbacks.Callback):\n",
    "    \"\"\"A callback to intentionally introduce interruption to training.\"\"\"\n",
    "    def on_epoch_end(self, epoch, log=None):\n",
    "        if epoch == 15:\n",
    "            raise RuntimeError('Interruption')\n",
    "\n",
    "model = keras.Sequential([keras.layers.Dense(10)])\n",
    "optimizer = keras.optimizers.SGD()\n",
    "model.compile(optimizer, loss=\"mse\")\n",
    "\n",
    "x = tf.random.uniform((24, 10))\n",
    "y = tf.random.uniform((24,))\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x, y)).repeat().batch(2)\n",
    "\n",
    "backup_callback = keras.callbacks.experimental.BackupAndRestore(\n",
    "    backup_dir='/tmp/backup')\n",
    "try:\n",
    "    model.fit(dataset, epochs=20, steps_per_epoch=5, \n",
    "            callbacks=[backup_callback, InterruptingCallback()])\n",
    "except RuntimeError:\n",
    "    print('***Handling interruption***')\n",
    "    # This continues at the epoch where it left off.\n",
    "    model.fit(dataset, epochs=20, steps_per_epoch=5, \n",
    "            callbacks=[backup_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-study",
   "metadata": {},
   "source": [
    "在回调文档中了解更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-washington",
   "metadata": {},
   "source": [
    "## 当验证损失不再减少时，如何中断训练？\n",
    "您可以使用 EarlyStopping 回调："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "model.fit(x, y, validation_split=0.2, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-shareware",
   "metadata": {},
   "source": [
    "在回调文档中了解更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-functionality",
   "metadata": {},
   "source": [
    "## 如何冻结图层并进行微调？\n",
    "### 设置可训练属性\n",
    "\n",
    "所有层和模型都有一个 layer.trainable 布尔属性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "worthy-script",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.58 ms (started: 2021-08-26 21:48:00 +08:00)\n"
     ]
    }
   ],
   "source": [
    "layer = keras.layers.Dense(3)\n",
    "layer.trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-inquiry",
   "metadata": {},
   "source": [
    "在所有层和模型上，可以设置可训练属性（为 True 或 False）。 当设置为 False 时， layer.trainable_weights 属性为空："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "monetary-syntax",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.9 ms (started: 2021-08-26 21:48:43 +08:00)\n"
     ]
    }
   ],
   "source": [
    "layer = keras.layers.Dense(3)\n",
    "layer.build(input_shape=(3, 3)) # Create the weights of the layer\n",
    "layer.trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "featured-hypothetical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
       " array([[-0.25013542,  0.4734645 , -0.29075813],\n",
       "        [-0.4378314 , -0.23321152,  0.52709436],\n",
       "        [-0.12084866,  0.53561974, -0.16229606]], dtype=float32)>,\n",
       " <tf.Variable 'bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.42 ms (started: 2021-08-26 21:48:53 +08:00)\n"
     ]
    }
   ],
   "source": [
    "layer.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "royal-entity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 658 µs (started: 2021-08-26 21:49:03 +08:00)\n"
     ]
    }
   ],
   "source": [
    "layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "outdoor-dispatch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.82 ms (started: 2021-08-26 21:49:11 +08:00)\n"
     ]
    }
   ],
   "source": [
    "layer.trainable_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfied-external",
   "metadata": {},
   "source": [
    "在图层上设置可训练属性会递归地将其设置在所有子图层（self.layers 的内容）上。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lovely-utility",
   "metadata": {},
   "source": [
    "1. 当用 fit() 训练时：\n",
    "\n",
    "要使用 fit() 进行微调，您将：\n",
    "* 实例化基本模型并加载预训练的权重\n",
    "* 冻结基本模型\n",
    "* 在顶部添加可训练层\n",
    "* 调用 `compile()` 和 `fit()`\n",
    "\n",
    "像这样："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    ResNet50Base(input_shape=(32, 32, 3), weights='pretrained'),\n",
    "    Dense(10),\n",
    "])\n",
    "model.layers[0].trainable = False  # Freeze ResNet50Base.\n",
    "\n",
    "assert model.layers[0].trainable_weights == []  # ResNet50Base has no trainable weights.\n",
    "assert len(model.trainable_weights) == 2  # Just the bias & kernel of the Dense layer.\n",
    "\n",
    "model.compile(...)\n",
    "model.fit(...)  # Train Dense while excluding ResNet50Base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-sperm",
   "metadata": {},
   "source": [
    "您可以使用 Functional API 或模型子类化 API 遵循类似的工作流程。 确保在更改 trainable 的值后调用 compile() 以便将您的更改考虑在内。 调用 compile() 将冻结模型训练步骤的状态。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-actor",
   "metadata": {},
   "source": [
    "2. 使用自定义训练循环时：\n",
    "\n",
    "在编写训练循环时，请确保仅更新属于 `model.trainable_weights`（而不是所有 `model.weights`）的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    ResNet50Base(input_shape=(32, 32, 3), weights='pretrained'),\n",
    "    Dense(10),\n",
    "])\n",
    "model.layers[0].trainable = False  # Freeze ResNet50Base.\n",
    "\n",
    "# Iterate over the batches of a dataset.\n",
    "for inputs, targets in dataset:\n",
    "    # Open a GradientTape.\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Forward pass.\n",
    "        predictions = model(inputs)\n",
    "        # Compute the loss value for this batch.\n",
    "        loss_value = loss_fn(targets, predictions)\n",
    "\n",
    "#     # Get gradients of loss wrt the *trainable* weights.\n",
    "#     gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "#     # Update the weights of the model.\n",
    "#     optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    optimizer.minimize(loss_value, model.trainable_weights, tape=tape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-humidity",
   "metadata": {},
   "source": [
    "### `trainable` 和 `compile()` 之间的交互\n",
    "\n",
    "在模型上调用 `compile()` 旨在“冻结”该模型的行为。 这意味着编译模型时的可训练属性值应在该模型的整个生命周期中保留，直到再次调用 `compile`。 因此，如果您更改可训练，请确保在您的模型上再次调用 `compile()` 以考虑您的更改。\n",
    "\n",
    "例如，如果两个模型 A 和 B 共享一些层，并且：\n",
    "* 模型 A 被编译\n",
    "* 共享层上的`trainable`属性值已更改\n",
    "* 模型B编译\n",
    "\n",
    "然后模型 A 和 B 为共享层使用不同的可训练值。 这种机制对于大多数现有的 GAN 实现至关重要，它们可以："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(...)  # the weights of `discriminator` should be updated when `discriminator` is trained\n",
    "discriminator.trainable = False\n",
    "gan.compile(...)  # `discriminator` is a submodel of `gan`, which should not be updated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-turkey",
   "metadata": {},
   "source": [
    "## `call()` 中的 `training` 参数和 `trainable` 属性之间有什么区别？\n",
    "`training` 是 `call` 中的一个布尔参数，用于确定调用应在推理模式还是训练模式下运行。 例如，在训练模式下，`Dropout` 层应用随机 `dropout` 并重新调整输出。 在推理模式下，同一层什么都不做。 例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noble-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = Dropout(0.5)(x, training=True)  # Applies dropout at training time *and* inference time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-monster",
   "metadata": {},
   "source": [
    "`trainable` 是一个布尔层属性，它确定应更新层的可训练权重以最小化训练期间的损失。 如果 `layer.trainable` 设置为 `False`，则 `layer.trainable_weights` 将始终是一个空列表。 例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    ResNet50Base(input_shape=(32, 32, 3), weights='pretrained'),\n",
    "    Dense(10),\n",
    "])\n",
    "model.layers[0].trainable = False  # Freeze ResNet50Base.\n",
    "\n",
    "assert model.layers[0].trainable_weights == []  # ResNet50Base has no trainable weights.\n",
    "assert len(model.trainable_weights) == 2  # Just the bias & kernel of the Dense layer.\n",
    "\n",
    "model.compile(...)\n",
    "model.fit(...)  # Train Dense while excluding ResNet50Base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-brass",
   "metadata": {},
   "source": [
    "如您所见，“推理模式与训练模式”和“层权重可训练性”是两个截然不同的概念。\n",
    "\n",
    "你可以想象如下：一个 `dropout` 层，在训练期间通过反向传播学习缩放因子。 我们将其命名为 AutoScaleDropout。 该层将同时具有可训练状态，以及推理和训练中的不同行为。 由于可训练属性和训练调用参数是独立的，您可以执行以下操作："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = AutoScaleDropout(0.5)\n",
    "\n",
    "# Applies dropout at training time *and* inference time  \n",
    "# *and* learns the scaling factor during training\n",
    "y = layer(x, training=True)\n",
    "\n",
    "assert len(layer.trainable_weights) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies dropout at training time *and* inference time  \n",
    "# with a *frozen* scaling factor\n",
    "\n",
    "layer = AutoScaleDropout(0.5)\n",
    "layer.trainable = False\n",
    "y = layer(x, training=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-mathematics",
   "metadata": {},
   "source": [
    "### `BatchNormalization` 层的特例\n",
    "\n",
    "考虑用于微调的模型冻结部分中的 `BatchNormalization` 层。\n",
    "\n",
    "`BatchNormalization` 层的移动统计数据是否应该保持冻结或适应新数据一直存在争议。 从历史上看，`bn.trainable = False` 只会停止反向传播，但不会阻止训练时间统计更新。 经过大量测试，我们发现在微调用例中冻结移动统计数据通常更好。 从 TensorFlow 2.0 开始，设置 `bn.trainable = False` 也会强制该层在推理模式下运行。\n",
    "\n",
    "此行为仅适用于 `BatchNormalization`。 对于其他每一层，权重可训练性和“推理与训练模式”保持独立。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "skilled-brooks",
   "metadata": {},
   "source": [
    "## 在 `fit()` 中，如何计算验证拆分？\n",
    "如果您将 `model.fit` 中的 `validation_split` 参数设置为例如 0.1，则使用的验证数据将是数据的最后 10%。 如果您将其设置为 0.25，它将是数据的最后 25%，等等。请注意，在提取验证拆分之前，数据并未打乱，因此验证实际上只是您输入中最后 x% 的样本 通过。\n",
    "\n",
    "相同的验证集用于所有时期（在同一个 `fit` 调用中）。\n",
    "\n",
    "请注意，仅当您的数据作为 Numpy 数组（不是 `tf.data.Datasets`，不可索引）传递时，`validation_split` 选项才可用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intermediate-gather",
   "metadata": {},
   "source": [
    "## 在 `fit()` 中，数据在训练期间是否打乱？\n",
    "如果您将数据作为 NumPy 数组传递，并且 `model.fit()` 中的 `shuffle` 参数设置为 `True`（这是默认值），则训练数据将在每个 `epoch` 全局随机打乱。\n",
    "\n",
    "如果您将数据作为 `tf.data.Dataset` 对象传递，并且 `model.fit()` 中的 shuffle 参数设置为 True，则数据集将在本地进行混洗（缓冲混洗）。\n",
    "\n",
    "使用 `tf.data.Dataset` 对象时，最好事先对数据进行混洗（例如，通过调用 `dataset = dataset.shuffle(buffer_size)）`以控制缓冲区大小。\n",
    "\n",
    "验证数据永远不会被打乱。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacterial-metro",
   "metadata": {},
   "source": [
    "## 使用 fit() 进行训练时，推荐的监控指标的方法是什么？\n",
    "损失值和度量值通过调用 fit() 显示的默认进度条报告。 但是，在控制台中盯着更改 ascii 数字并不是最佳的指标监控体验。 我们建议使用 TensorBoard，它将显示漂亮的训练和验证指标图表，在训练期间定期更新，您可以从浏览器访问这些图表。\n",
    "\n",
    "您可以通过 TensorBoard 回调将 TensorBoard 与 fit() 结合使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-printer",
   "metadata": {},
   "source": [
    "##  如果我需要自定义 `fit()` 的功能怎么办？\n",
    "您有两个选择：\n",
    "\n",
    "1. 编写一个低级自定义训练循环\n",
    "\n",
    "如果您想控制每一个最后的小细节，这是一个不错的选择。 但它可能有点冗长。 例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备一个优化器。\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# Prepare a loss function.\n",
    "loss_fn = tf.keras.losses.kl_divergence\n",
    "\n",
    "# 迭代数据集的批次。\n",
    "for inputs, targets in dataset:\n",
    "    # 打开一个 GradientTape。\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 前向传递\n",
    "        predictions = model(inputs)\n",
    "        # 计算该批次的损失值。\n",
    "        loss_value = loss_fn(targets, predictions)\n",
    "\n",
    "    # 获取权重的损失梯度。\n",
    "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "    # 更新模型的权重。\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-calculation",
   "metadata": {},
   "source": [
    "此示例不包括许多基本功能，例如显示进度条、调用回调、更新指标等。您必须自己执行此操作。 这一点都不难，但有点工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-berkeley",
   "metadata": {},
   "source": [
    "2. 子类模型类并覆盖`train_step`（和`test_step`）方法\n",
    "\n",
    "如果您想使用自定义更新规则但仍想利用 `fit()` 提供的功能，例如回调、高效步骤融合等，这是一个更好的选择。\n",
    "\n",
    "请注意，此模式不会阻止您使用 Functional API（甚至是 Sequential 模型）构建模型。\n",
    "\n",
    "下面的示例显示了具有自定义 `train_step` 的功能模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bored-opera",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 2s 12ms/step - loss: 0.4085 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.2021 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1915 - accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1871 - accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1827 - accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1783 - accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1738 - accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1692 - accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1647 - accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1601 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5d7408c4c0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.18 s (started: 2021-08-26 22:27:57 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class MyCustomModel(keras.Model):\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # 解压数据。 它的结构取决于您的模型以及您传递给 `fit()` 的内容。\n",
    "        x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # 计算损失值（损失函数在`compile()`中配置）\n",
    "            loss = self.compiled_loss(y, y_pred,\n",
    "                                      regularization_losses=self.losses)\n",
    "\n",
    "        # 计算梯度\n",
    "        trainable_vars = self.trainable_variables\n",
    "#         gradients = tape.gradient(loss, trainable_vars)\n",
    "        # 更新权重\n",
    "#         self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        self.optimizer.minimize(loss, trainable_vars, tape = tape)\n",
    "        # 更新指标（包括跟踪损失的指标）\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # 将字典映射度量名称返回到当前值\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "# 构造并编译 MyCustomModel 的一个实例\n",
    "inputs = keras.Input(shape=(32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = MyCustomModel(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# 像往常一样使用`fit`\n",
    "x = np.random.random((1000, 32))\n",
    "y = np.random.random((1000, 1))\n",
    "model.fit(x, y, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-senator",
   "metadata": {},
   "source": [
    "您还可以轻松添加对样本加权的支持："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-rover",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomModel(keras.Model):\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack the data. Its structure depends on your model and\n",
    "        # on what you pass to `fit()`.\n",
    "        if len(data) == 3:\n",
    "            x, y, sample_weight = data\n",
    "        else:\n",
    "            x, y = data\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            # Compute the loss value.\n",
    "            # The loss function is configured in `compile()`.\n",
    "            loss = self.compiled_loss(y, y_pred,\n",
    "                                      sample_weight=sample_weight,\n",
    "                                      regularization_losses=self.losses)\n",
    "\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update the metrics.\n",
    "        # Metrics are configured in `compile()`.\n",
    "        self.compiled_metrics.update_state(\n",
    "            y, y_pred, sample_weight=sample_weight)\n",
    "\n",
    "        # Return a dict mapping metric names to current value.\n",
    "        # Note that it will include the loss (tracked in self.metrics).\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "    \n",
    "# Construct and compile an instance of MyCustomModel\n",
    "inputs = keras.Input(shape=(32,))\n",
    "outputs = keras.layers.Dense(1)(inputs)\n",
    "model = MyCustomModel(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# You can now use sample_weight argument\n",
    "x = np.random.random((1000, 32))\n",
    "y = np.random.random((1000, 1))\n",
    "sw = np.random.random((1000, 1))\n",
    "model.fit(x, y, sample_weight=sw, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-contrast",
   "metadata": {},
   "source": [
    "同样，您也可以通过覆盖 test_step 来自定义评估："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomModel(keras.Model):\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "        # Compute predictions\n",
    "        y_pred = self(x, training=False)\n",
    "        # Updates the metrics tracking the loss\n",
    "        self.compiled_loss(\n",
    "          y, y_pred, regularization_losses=self.losses)\n",
    "        # Update the metrics.\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value.\n",
    "        # Note that it will include the loss (tracked in self.metrics).\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-lecture",
   "metadata": {},
   "source": [
    "## 如何以混合精度训练模型？\n",
    "Keras 内置支持在 GPU 和 TPU 上进行混合精度训练。 请参阅此详尽指南。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-township",
   "metadata": {},
   "source": [
    "# 建模相关问题\n",
    "## 如何获得中间层的输出（特征提取）？\n",
    "在 Functional API 和 Sequential API 中，如果一个层被调用了一次，你可以通过 `layer.output` 检索它的输出，通过 `layer.input` 检索它的输入。 这使您能够快速实例化特征提取模型，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.GlobalMaxPooling2D(),\n",
    "    layers.Dense(10),\n",
    "])\n",
    "extractor = keras.Model(inputs=model.inputs,\n",
    "                        outputs=[layer.output for layer in model.layers])\n",
    "features = extractor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-resolution",
   "metadata": {},
   "source": [
    "自然，这对于作为覆盖调用的 Model 子类的模型是不可能的。\n",
    "\n",
    "这是另一个示例：实例化一个返回特定命名层输出的模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-replacement",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ...  # create the original model\n",
    "\n",
    "layer_name = 'my_layer'\n",
    "intermediate_layer_model = keras.Model(inputs=model.input,\n",
    "                                       outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specified-research",
   "metadata": {},
   "source": [
    "## 如何在 Keras 中使用预训练模型？\n",
    "您可以利用 keras.applications 中可用的模型，或 TensorFlow Hub 上可用的模型。 TensorFlow Hub 与 Keras 集成良好。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-institution",
   "metadata": {},
   "source": [
    "## 如何使用有状态的 RNN？\n",
    "使 RNN 有状态意味着每批样本的状态将被重用作为下一批样本的初始状态。\n",
    "\n",
    "因此，在使用有状态 RNN 时，假设：\n",
    "* 所有批次的样品数量相同\n",
    "* 如果 x1 和 x2 是连续批次的样本，则 x2[i] 是 x1[i] 的后续序列，对于每个 i。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-favor",
   "metadata": {},
   "source": [
    "要在 RNN 中使用状态性，您需要：\n",
    "* 通过将 `batch_size` 参数传递给模型中的第一层，明确指定您正在使用的批量大小。 例如。 `batch_size=32` 用于 10 个时间步长的 32 个样本批次序列，每个时间步长有 16 个特征。\n",
    "* 在您的 RNN 层中设置 `stateful=True`。\n",
    "* 调用 `fit()` 时指定 `shuffle=False`。\n",
    "\n",
    "要重置累积的状态：\n",
    "* 使用 `model.reset_states()` 重置模型中所有层的状态\n",
    "* 使用 `layer.reset_states()` 重置特定有状态 RNN 层的状态\n",
    "\n",
    "例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "loved-giving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3 s (started: 2021-08-26 22:42:39 +08:00)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.random((32, 21, 16)) # 这是我们的输入数据，形状为 (32, 21, 16)\n",
    "# 我们将把它以长度为 10 的序列提供给我们的模型\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.LSTM(32, input_shape=(10, 16), batch_size=32, stateful=True))\n",
    "model.add(layers.Dense(16, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "# 我们训练网络在给定前 10 个时间步长的情况下预测第 11 个时间步长：\n",
    "model.train_on_batch(x[:, :10, :], np.reshape(x[:, 10, :], (32, 16)))\n",
    "\n",
    "# 网络状态发生了变化。 我们可以提供后续序列：\n",
    "model.train_on_batch(x[:, 10:20, :], np.reshape(x[:, 20, :], (32, 16)))\n",
    "\n",
    "# 让我们重置 LSTM 层的状态：\n",
    "model.reset_states()\n",
    "\n",
    "# 在这种情况下的另一种方法：\n",
    "model.layers[0].reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-queensland",
   "metadata": {},
   "source": [
    "请注意，方法 `predict、fit、train_on_batch` 等都会更新模型中状态层的状态。 这使您不仅可以进行有状态训练，还可以进行有状态预测。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
