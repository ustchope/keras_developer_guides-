{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "further-designation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 701 ms (started: 2021-08-26 15:51:35 +08:00)\n"
     ]
    }
   ],
   "source": [
    "# 自动计算cell的计算时间\n",
    "%load_ext autotime\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='svg' #矢量图设置，让绘图更清晰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "experienced-opportunity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin\tgit@github.com:ustchope/keras_developer_guides-.git (fetch)\n",
      "origin\tgit@github.com:ustchope/keras_developer_guides-.git (push)\n",
      "[main 0144e9e] 更新 #5  Aug 26, 2021\n",
      " 3 files changed, 1367 insertions(+), 39 deletions(-)\n",
      " create mode 100644 \"\\344\\275\\277\\347\\224\\250 RNN.ipynb\"\n",
      " create mode 100644 \"\\344\\275\\277\\347\\224\\250\\351\\242\\204\\345\\244\\204\\347\\220\\206\\345\\261\\202.ipynb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To git@github.com:ustchope/keras_developer_guides-.git\n",
      "   8790ccd..0144e9e  main -> main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.28 s (started: 2021-08-26 15:51:46 +08:00)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# 增加更新\n",
    "git add *.ipynb *.md\n",
    "\n",
    "git remote -v\n",
    "\n",
    "git commit -m '更新 #5  Aug 26, 2021'\n",
    "\n",
    "#git push origin master\n",
    "git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "furnished-franchise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.93 s (started: 2021-08-26 15:52:01 +08:00)\n"
     ]
    }
   ],
   "source": [
    "#设置使用的gpu\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "\n",
    "if gpus:\n",
    "   \n",
    "    gpu0 = gpus[0] #如果有多个GPU，仅使用第0个GPU\n",
    "    tf.config.experimental.set_memory_growth(gpu0, True) #设置GPU显存用量按需使用\n",
    "    # 或者也可以设置GPU显存为固定使用量(例如：4G)\n",
    "    #tf.config.experimental.set_virtual_device_configuration(gpu0,\n",
    "    #    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)]) \n",
    "    tf.config.set_visible_devices([gpu0],\"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-consultation",
   "metadata": {},
   "source": [
    "# 介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-flavor",
   "metadata": {},
   "source": [
    "循环神经网络 (RNN) 是一类强大的神经网络，可用于对时间序列或自然语言等序列数据进行建模。\n",
    "\n",
    "从原理上讲，RNN 层使用 for 循环来迭代序列的时间步长，同时保持一个内部状态，该状态对有关它迄今为止看到的时间步长的信息进行编码。\n",
    "\n",
    "Keras RNN API 的设计重点是：\n",
    "* **易用性：** 内置的 `keras.layers.RNN`、`keras.layers.LSTM`、`keras.layers.GRU` 层使您能够快速构建循环模型，而无需做出困难的配置选择。\n",
    "* **易于定制：** 您还可以使用自定义行为定义自己的 RNN 单元层（for 循环的内部部分），并将其与通用 `keras.layers.RNN` 层（for 循环本身）一起使用。 这使您可以使用最少的代码以灵活的方式快速对不同的研究想法进行原型设计。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-turkish",
   "metadata": {},
   "source": [
    "# 设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "positive-bracelet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 386 µs (started: 2021-08-26 15:54:25 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-findings",
   "metadata": {},
   "source": [
    "# 内置 RNN 层：一个简单的例子"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-israel",
   "metadata": {},
   "source": [
    "Keras 中内置了三个 RNN 层：\n",
    "\n",
    "1. keras.layers.SimpleRNN，一个全连接的 RNN，其中前一个时间步的输出将被馈送到下一个时间步。\n",
    "2. keras.layers.GRU，在 Cho 等人，2014 年首次提出。\n",
    "3. keras.layers.LSTM，首先在 Hochreiter & Schmidhuber 中提出，1997 年。\n",
    "\n",
    "2015 年初，Keras 拥有第一个 LSTM 和 GRU 的可重用开源 Python 实现。\n",
    "\n",
    "这是一个 Sequential 模型的简单示例，该模型处理整数序列，将每个整数嵌入到 64 维向量中，然后使用 LSTM 层处理向量序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fantastic-schedule",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 164,106\n",
      "Trainable params: 164,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "time: 2.15 s (started: 2021-08-26 15:56:48 +08:00)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# 添加一个 Embedding 层，期望输入大小为 1000 的词汇，然后大小为 64 的输出嵌入维度。\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# 添加一个具有 128 个内部单元的 LSTM 层。\n",
    "model.add(layers.LSTM(128))\n",
    "\n",
    "# Add a Dense layer with 10 units.\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-wonder",
   "metadata": {},
   "source": [
    "内置 RNN 支持许多有用的功能：\n",
    "* 循环 dropout，通过 dropout 和 recurrent_dropout 参数\n",
    "* 通过 go_backwards 参数反向处理输入序列的能力\n",
    "* 通过 unroll 参数循环展开（在 CPU 上处理短序列时可能会导致大幅加速）\n",
    "* ...和更多。\n",
    "\n",
    "有关更多信息，请参阅 RNN API 文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-harris",
   "metadata": {},
   "source": [
    "# 输出和状态"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-bench",
   "metadata": {},
   "source": [
    "默认情况下，RNN 层的输出每个样本包含一个向量。 该向量是对应于最后一个时间步的 RNN 单元输出，包含有关整个输入序列的信息。 此输出的形状是 `(batch_size, units)`，其中单位对应于传递给层构造函数的单位参数。\n",
    "\n",
    "如果设置 `return_sequences=True`，RNN 层还可以返回每个样本的整个输出序列（每个样本每个时间步一个向量）。 此输出的形状是 (`batch_size, timesteps, units`)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "functional-hearts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, None, 256)         247296    \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 128)               49280     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 361,866\n",
      "Trainable params: 361,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "time: 416 ms (started: 2021-08-26 16:00:56 +08:00)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
    "model.add(layers.GRU(256, return_sequences=True))\n",
    "\n",
    "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
    "model.add(layers.SimpleRNN(128))\n",
    "\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-trustee",
   "metadata": {},
   "source": [
    "此外，RNN 层可以返回其最终内部状态。 返回的状态可用于稍后恢复 RNN 执行，或初始化另一个 RNN。 此设置通常用于编码器-解码器序列到序列模型，其中编码器最终状态用作解码器的初始状态。\n",
    "\n",
    "要将 RNN 层配置为返回其内部状态，请在创建层时将 return_state 参数设置为 True。 请注意，LSTM 有 2 个状态张量，但 GRU 只有一个。\n",
    "\n",
    "要配置层的初始状态，只需使用附加关键字参数 initial_state 调用层。 请注意，状态的形状需要与图层的单位大小相匹配，如下例所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "random-webster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 64)     64000       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 64)     128000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder (LSTM)                  [(None, 64), (None,  33024       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  (None, 64)           33024       embedding_3[0][0]                \n",
      "                                                                 encoder[0][1]                    \n",
      "                                                                 encoder[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           650         decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 258,698\n",
      "Trainable params: 258,698\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "time: 607 ms (started: 2021-08-26 16:04:06 +08:00)\n"
     ]
    }
   ],
   "source": [
    "encoder_vocab = 1000\n",
    "decoder_vocab = 2000\n",
    "\n",
    "encoder_input = layers.Input(shape=(None,))\n",
    "encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(\n",
    "    encoder_input\n",
    ")\n",
    "\n",
    "# 除了输出还返回状态\n",
    "output, state_h, state_c = layers.LSTM(64, return_state=True, name=\"encoder\")(\n",
    "    encoder_embedded\n",
    ")\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "decoder_input = layers.Input(shape=(None,))\n",
    "decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=64)(\n",
    "    decoder_input\n",
    ")\n",
    "\n",
    "# 将 2 个状态传递给新的 LSTM 层，作为初始状态\n",
    "decoder_output = layers.LSTM(64, name=\"decoder\")(\n",
    "    decoder_embedded, initial_state=encoder_state\n",
    ")\n",
    "output = layers.Dense(10)(decoder_output)\n",
    "\n",
    "model = keras.Model([encoder_input, decoder_input], output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-beads",
   "metadata": {},
   "source": [
    "# RNN 层和 RNN 单元"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "featured-camping",
   "metadata": {},
   "source": [
    "除了内置的 RNN 层外，RNN API 还提供单元级 API。 与处理整批输入序列的 RNN 层不同，RNN 单元只处理单个时间步长。\n",
    "\n",
    "单元格位于 RNN 层的 for 循环内部。 将一个单元包装在 `keras.layers.RNN` 层中可以为您提供一个能够处理批量序列的层，例如 `RNN(LSTMCell(10))`。\n",
    "\n",
    "在数学上，`RNN(LSTMCell(10))` 产生与 `LSTM(10)` 相同的结果。 实际上，TF v1.x 中这一层的实现只是创建了相应的 RNN 单元并将其包裹在一个 RNN 层中。 然而，使用内置的 GRU 和 LSTM 层可以使用 CuDNN，您可能会看到更好的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-education",
   "metadata": {},
   "source": [
    "内置了三个 RNN 单元，每个单元对应匹配的 RNN 层。\n",
    "* `keras.layers.SimpleRNNCell` 对应于 SimpleRNN 层。\n",
    "* `keras.layers.GRUCell` 对应 GRU 层。\n",
    "* `keras.layers.LSTMCell` 对应LSTM层。\n",
    "单元抽象与通用 `keras.layers.RNN` 类一起，使为您的研究实现自定义 RNN 架构变得非常容易。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-composer",
   "metadata": {},
   "source": [
    "# 跨批次状态"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-logistics",
   "metadata": {},
   "source": [
    "在处理很长的序列（可能是无限的）时，您可能希望使用跨批次状态的模式。\n",
    "\n",
    "通常，RNN 层的内部状态在每次看到新批次时都会重置（即假设该层看到的每个样本都与过去无关）。 该层只会在处理给定样本时保持状态。\n",
    "\n",
    "但是，如果您有很长的序列，将它们分解成较短的序列，并将这些较短的序列按顺序输入 RNN 层而不重置层的状态是很有用的。 这样，该层可以保留有关整个序列的信息，即使它一次只能看到一个子序列。\n",
    "\n",
    "您可以通过在构造函数中设置 `stateful=True` 来做到这一点。\n",
    "\n",
    "如果您有一个序列 s = [t0, t1, ... t1546, t1547]，您可以将其拆分为例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = [t0, t1, ... t100]\n",
    "s2 = [t101, ... t201]\n",
    "...\n",
    "s16 = [t1501, ... t1547]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-hammer",
   "metadata": {},
   "source": [
    "然后您将通过以下方式处理它："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer = layers.LSTM(64, stateful=True)\n",
    "for s in sub_sequences:\n",
    "    output = lstm_layer(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-stuart",
   "metadata": {},
   "source": [
    "当你想清除状态时，你可以使用 `layer.reset_states()`。\n",
    "\n",
    "> 注意：在此设置中，给定批次中的样本 i 被假定为上一批次中样本 i 的延续。 这意味着所有批次都应包含相同数量的样本（批次大小）。 例如。 如果批次包含 [sequence_A_from_t0_to_t100, sequence_B_from_t0_to_t100]，则下一批应包含 [sequence_A_from_t101_to_t200, sequence_B_from_t101_to_t200]。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-austin",
   "metadata": {},
   "source": [
    "这是一个完整的例子："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "civilian-adult",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.39 s (started: 2021-08-26 16:09:29 +08:00)\n"
     ]
    }
   ],
   "source": [
    "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "\n",
    "lstm_layer = layers.LSTM(64, stateful=True)\n",
    "output = lstm_layer(paragraph1)\n",
    "output = lstm_layer(paragraph2)\n",
    "output = lstm_layer(paragraph3)\n",
    "\n",
    "# reset_states() 将缓存状态重置为原始initial_state。\n",
    "# 如果没有提供initial_state，则默认使用零状态。\n",
    "lstm_layer.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-prophet",
   "metadata": {},
   "source": [
    "## RNN 状态重用\n",
    "RNN 层的记录状态不包含在 `layer.weights()` 中。 如果您想重用 RNN 层的状态，您可以通过 `layer.states` 检索状态值，并通过 Keras 函数 API 将其用作新层的初始状态，例如 `new_layer(inputs, initial_state=layer.states)` ，或模型子类化。\n",
    "\n",
    "还请注意，在这种情况下可能不会使用顺序模型，因为它只支持具有单一输入和输出的层，初始状态的额外输入使得这里无法使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "weekly-interaction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 69.2 ms (started: 2021-08-26 16:10:32 +08:00)\n"
     ]
    }
   ],
   "source": [
    "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "\n",
    "lstm_layer = layers.LSTM(64, stateful=True)\n",
    "output = lstm_layer(paragraph1)\n",
    "output = lstm_layer(paragraph2)\n",
    "\n",
    "existing_state = lstm_layer.states\n",
    "\n",
    "new_lstm_layer = layers.LSTM(64)\n",
    "new_output = new_lstm_layer(paragraph3, initial_state=existing_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-gossip",
   "metadata": {},
   "source": [
    "# 双向 RNN\n",
    "对于时间序列以外的序列（例如文本），通常情况下，如果 RNN 模型不仅从头到尾处理序列，而且还向后处理，则它的性能会更好。 例如，要预测句子中的下一个单词，拥有单词周围的上下文通常很有用，而不仅仅是它前面的单词。\n",
    "\n",
    "Keras 为您提供了一个简单的 API 来构建这种双向 RNN：`keras.layers.Bidirectional` 包装器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "judicial-holly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 5, 128)            38400     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 80,266\n",
      "Trainable params: 80,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "time: 793 ms (started: 2021-08-26 16:11:06 +08:00)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(\n",
    "    layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(5, 10))\n",
    ")\n",
    "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-mistress",
   "metadata": {},
   "source": [
    "在幕后，`Bidirectional` 将复制传入的 RNN 层，并翻转新复制层的 `go_backwards` 字段，以便它以相反的顺序处理输入。\n",
    "\n",
    "默认情况下，双向 RNN 的输出将是前向层输出和后向层输出的串联。 如果您需要不同的合并行为，例如 串联，更改双向包装器构造函数中的 `merge_mode` 参数。 有关双向的更多详细信息，请查看 API 文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-saver",
   "metadata": {},
   "source": [
    "# 性能优化和 CuDNN 内核\n",
    "在 TensorFlow 2.0 中，内置 LSTM 和 GRU 层已更新，以在 GPU 可用时默认利用 CuDNN 内核。 通过此更改，先前的 `keras.layers.CuDNNLSTM/CuDNNGRU` 层已被弃用，您可以构建模型而无需担心它将运行的硬件。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-prior",
   "metadata": {},
   "source": [
    "由于 CuDNN 内核是在某些假设下构建的，这意味着如果您更改内置 LSTM 或 GRU 层的默认值，该层将无法使用 CuDNN 内核。 例如。：\n",
    "* 将激活函数从 tanh 更改为其他内容。\n",
    "* 将 recurrent_activation 函数从 sigmoid 更改为其他函数。\n",
    "* 使用 recurrent_dropout > 0。\n",
    "* 将 unroll 设置为 True，这会强制 LSTM/GRU 将内部 tf.while_loop 分解为一个展开的 for 循环。\n",
    "* 将 use_bias 设置为 False。\n",
    "* 当输入数据没有严格右填充时使用掩码（如果掩码对应于严格右填充的数据，仍然可以使用 CuDNN。这是最常见的情况）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-italian",
   "metadata": {},
   "source": [
    "有关约束的详细列表，请参阅 LSTM 和 GRU 层的文档。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-robinson",
   "metadata": {},
   "source": [
    "## 在可用时使用 CuDNN 内核\n",
    "让我们构建一个简单的 LSTM 模型来演示性能差异。\n",
    "\n",
    "我们将使用 MNIST 数字行的序列作为输入序列（将每一行像素视为一个时间步长），我们将预测数字的标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "colonial-failure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.19 ms (started: 2021-08-26 16:15:08 +08:00)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "# 每个 MNIST 图像批次都是一个形状张量 (batch_size, 28, 28)。\n",
    "# 每个输入序列的大小为 (28, 28)（高度被视为时间）。\n",
    "input_dim = 28\n",
    "\n",
    "units = 64\n",
    "output_size = 10  # labels are from 0 to 9\n",
    "\n",
    "# Build the RNN model\n",
    "def build_model(allow_cudnn_kernel=True):\n",
    "    # CuDNN 仅在层级可用，在单元级不可用。\n",
    "    # 这意味着 `LSTM(units)` 将使用 CuDNN 内核，\n",
    "    # 而 RNN(LSTMCell(units)) 将在非 CuDNN 内核上运行。\n",
    "    if allow_cudnn_kernel:\n",
    "        # 带有默认选项的 LSTM 层使用 CuDNN。\n",
    "        lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
    "    else:\n",
    "        # 将 LSTMCell 包装在 RNN 层中将不会使用 CuDNN。\n",
    "        lstm_layer = keras.layers.RNN(\n",
    "            keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
    "        )\n",
    "    model = keras.models.Sequential(\n",
    "        [\n",
    "            lstm_layer,\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dense(output_size),\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-iceland",
   "metadata": {},
   "source": [
    "让我们加载 MNIST 数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "surprised-three",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 669 ms (started: 2021-08-26 16:15:27 +08:00)\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "sample, sample_label = x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-january",
   "metadata": {},
   "source": [
    "让我们创建一个模型实例并训练它。\n",
    "\n",
    "我们选择 `sparse_categorical_crossentropy` 作为模型的损失函数。 模型的输出形状为 [batch_size, 10]。 模型的目标是一个整数向量，每个整数在 0 到 9 的范围内。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "satisfactory-thanksgiving",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 17s 13ms/step - loss: 0.9818 - accuracy: 0.6890 - val_loss: 0.5344 - val_accuracy: 0.8325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8e800edd90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18.1 s (started: 2021-08-26 16:15:53 +08:00)\n"
     ]
    }
   ],
   "source": [
    "model = build_model(allow_cudnn_kernel=True)\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-optimization",
   "metadata": {},
   "source": [
    "现在，让我们与不使用 CuDNN 内核的模型进行比较："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "rising-death",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 46s 48ms/step - loss: 0.3809 - accuracy: 0.8861 - val_loss: 0.2800 - val_accuracy: 0.9089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8e80052520>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 46.7 s (started: 2021-08-26 16:16:34 +08:00)\n"
     ]
    }
   ],
   "source": [
    "noncudnn_model = build_model(allow_cudnn_kernel=False)\n",
    "noncudnn_model.set_weights(model.get_weights())\n",
    "\n",
    "noncudnn_model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "noncudnn_model.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-mainstream",
   "metadata": {},
   "source": [
    "当在安装了 NVIDIA GPU 和 CuDNN 的机器上运行时，与使用常规 TensorFlow 内核的模型相比，使用 CuDNN 构建的模型的训练速度要快得多。\n",
    "\n",
    "相同的启用了 CuDNN 的模型也可用于在仅 CPU 的环境中运行推理。 下面的`tf.device` 注释只是强制放置设备。 如果没有可用的 GPU，该模型将默认在 CPU 上运行。\n",
    "\n",
    "您根本不必再担心正在运行的硬件。 这不是很酷吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "handed-standard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted result is: [3], target result is: 5\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2021-08-26T16:18:01.849895</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 248.518125 \n",
       "L 251.565 248.518125 \n",
       "L 251.565 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 26.925 224.64 \n",
       "L 244.365 224.64 \n",
       "L 244.365 7.2 \n",
       "L 26.925 7.2 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p357b8f92c1)\">\n",
       "    <image height=\"218\" id=\"image329a1f4c66\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\n",
       "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\" y=\"-6.64\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m51981f1d74\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m51981f1d74\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m51981f1d74\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m51981f1d74\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m51981f1d74\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m51981f1d74\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m51981f1d74\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m491cc159c3\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m491cc159c3\" y=\"11.082857\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m491cc159c3\" y=\"49.911429\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m491cc159c3\" y=\"88.74\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m491cc159c3\" y=\"127.568571\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m491cc159c3\" y=\"166.397143\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m491cc159c3\" y=\"205.225714\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 26.925 224.64 \n",
       "L 26.925 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 244.365 224.64 \n",
       "L 244.365 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 26.925 224.64 \n",
       "L 244.365 224.64 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 26.925 7.2 \n",
       "L 244.365 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p357b8f92c1\">\n",
       "   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 956 ms (started: 2021-08-26 16:18:00 +08:00)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with tf.device(\"CPU:0\"):\n",
    "    cpu_model = build_model(allow_cudnn_kernel=True)\n",
    "    cpu_model.set_weights(model.get_weights())\n",
    "    result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, 0)), axis=1)\n",
    "    print(\n",
    "        \"Predicted result is: %s, target result is: %s\" % (result.numpy(), sample_label)\n",
    "    )\n",
    "    plt.imshow(sample, cmap=plt.get_cmap(\"gray\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-royal",
   "metadata": {},
   "source": [
    "# 具有列表/字典输入或嵌套输入的 RNN\n",
    "嵌套结构允许实现者在单个时间步长内包含更多信息。 例如，视频帧可以同时具有音频和视频输入。 这种情况下的数据形状可能是：\n",
    "\n",
    "[batch, timestep, {\"video\": [height, width, channel], \"audio\": [频率]}]\n",
    "\n",
    "在另一个示例中，手写数据可以同时具有笔当前位置的坐标 x 和 y，以及压力信息。 所以数据表示可以是：\n",
    "\n",
    "[批次，时间步长，{“位置”：[x，y]，“压力”：[力]}]\n",
    "\n",
    "以下代码提供了如何构建接受此类结构化输入的自定义 RNN 单元的示例。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-cocktail",
   "metadata": {},
   "source": [
    "## 定义支持嵌套输入/输出的自定义单元格\n",
    "有关编写自己的层的详细信息，请参阅通过子类创建新层和模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "defensive-underground",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.11 ms (started: 2021-08-26 16:21:12 +08:00)\n"
     ]
    }
   ],
   "source": [
    "class NestedCell(keras.layers.Layer):\n",
    "    def __init__(self, unit_1, unit_2, unit_3, **kwargs):\n",
    "        self.unit_1 = unit_1\n",
    "        self.unit_2 = unit_2\n",
    "        self.unit_3 = unit_3\n",
    "        self.state_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n",
    "        self.output_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n",
    "        super(NestedCell, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shapes):\n",
    "        # 期望 input_shape 包含 2 个项目，[(batch, i1), (batch, i2, i3)]\n",
    "        i1 = input_shapes[0][1]\n",
    "        i2 = input_shapes[1][1]\n",
    "        i3 = input_shapes[1][2]\n",
    "\n",
    "        self.kernel_1 = self.add_weight(\n",
    "            shape=(i1, self.unit_1), initializer=\"uniform\", name=\"kernel_1\"\n",
    "        )\n",
    "        self.kernel_2_3 = self.add_weight(\n",
    "            shape=(i2, i3, self.unit_2, self.unit_3),\n",
    "            initializer=\"uniform\",\n",
    "            name=\"kernel_2_3\",\n",
    "        )\n",
    "\n",
    "    def call(self, inputs, states):\n",
    "        # 输入应该在 [(batch, input_1), (batch, input_2, input_3)]\n",
    "        # 状态应该是 [(batch, unit_1), (batch, unit_2, unit_3)]\n",
    "        input_1, input_2 = tf.nest.flatten(inputs)\n",
    "        s1, s2 = states\n",
    "\n",
    "        output_1 = tf.matmul(input_1, self.kernel_1)\n",
    "        output_2_3 = tf.einsum(\"bij,ijkl->bkl\", input_2, self.kernel_2_3)\n",
    "        state_1 = s1 + output_1\n",
    "        state_2_3 = s2 + output_2_3\n",
    "\n",
    "        output = (output_1, output_2_3)\n",
    "        new_states = (state_1, state_2_3)\n",
    "\n",
    "        return output, new_states\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"unit_1\": self.unit_1, \"unit_2\": unit_2, \"unit_3\": self.unit_3}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-hindu",
   "metadata": {},
   "source": [
    "## 构建具有嵌套输入/输出的 RNN 模型\n",
    "让我们构建一个使用 keras.layers.RNN 层和我们刚刚定义的自定义单元格的 Keras 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ruled-praise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 201 ms (started: 2021-08-26 16:22:19 +08:00)\n"
     ]
    }
   ],
   "source": [
    "unit_1 = 10\n",
    "unit_2 = 20\n",
    "unit_3 = 30\n",
    "\n",
    "i1 = 32\n",
    "i2 = 64\n",
    "i3 = 32\n",
    "batch_size = 64\n",
    "num_batches = 10\n",
    "timestep = 50\n",
    "\n",
    "cell = NestedCell(unit_1, unit_2, unit_3)\n",
    "rnn = keras.layers.RNN(cell)\n",
    "\n",
    "input_1 = keras.Input((None, i1))\n",
    "input_2 = keras.Input((None, i2, i3))\n",
    "\n",
    "outputs = rnn((input_1, input_2))\n",
    "\n",
    "model = keras.models.Model([input_1, input_2], outputs)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-camping",
   "metadata": {},
   "source": [
    "## 使用随机生成的数据训练模型\n",
    "由于此模型没有好的候选数据集，我们使用随机 Numpy 数据进行演示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "contemporary-turkey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 42ms/step - loss: 0.7565 - rnn_1_loss: 0.2793 - rnn_1_1_loss: 0.4773 - rnn_1_accuracy: 0.0828 - rnn_1_1_accuracy: 0.0319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8dec063970>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.8 s (started: 2021-08-26 16:23:12 +08:00)\n"
     ]
    }
   ],
   "source": [
    "input_1_data = np.random.random((batch_size * num_batches, timestep, i1))\n",
    "input_2_data = np.random.random((batch_size * num_batches, timestep, i2, i3))\n",
    "target_1_data = np.random.random((batch_size * num_batches, unit_1))\n",
    "target_2_data = np.random.random((batch_size * num_batches, unit_2, unit_3))\n",
    "input_data = [input_1_data, input_2_data]\n",
    "target_data = [target_1_data, target_2_data]\n",
    "\n",
    "model.fit(input_data, target_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-traffic",
   "metadata": {},
   "source": [
    "使用`Keras keras.layers.RNN` 层，您只需为序列中的各个步骤定义数学逻辑，`keras.layers.RNN` 层将为您处理序列迭代。 这是一种快速构建新型 RNN（例如 LSTM 变体）原型的非常强大的方法。\n",
    "\n",
    "有关更多详细信息，请访问 API 文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-alexander",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
